{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "You are to predict whether a company will go bankrupt in the following year, based on financial attributes of the company.\n",
    "\n",
    "Perhaps you are contemplating lending money to a company, and need to know whether the company\n",
    "is in near-term danger of not being able to repay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Learning objectives\n",
    "\n",
    "- Demonstrate mastery on solving a classification problem and presenting\n",
    "the entire Recipe for Machine Learning process in a notebook.\n",
    "- We will make suggestions for ways to approach the problem\n",
    "    - But there will be little explicit direction for this task.\n",
    "- It is meant to be analogous to a pre-interview task that a potential employer might assign\n",
    "to verify your skill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import os\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API for students"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the bankruptcy_helper module\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Import bankruptcy_helper module\n",
    "import bankruptcy_helper\n",
    "%aimport bankruptcy_helper\n",
    "\n",
    "helper = bankruptcy_helper.Helper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "\n",
    "The first step in our Recipe is Get the Data.\n",
    "\n",
    "- Each example is a row of data corresponding to a single company\n",
    "- There are 64 attributes, described in the section below\n",
    "- The column `Bankrupt` is 1 if the company subsequently went bankrupt; 0 if it did not go bankrupt\n",
    "- The column `Id` is a Company Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date shape:  (4818, 66)\n"
     ]
    }
   ],
   "source": [
    "# Data directory\n",
    "DATA_DIR = \"./Data\"\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    DATA_DIR = \"../resource/asnlib/publicdata/bankruptcy/data\"\n",
    "\n",
    "data_file = \"5th_yr.csv\"\n",
    "data = pd.read_csv( os.path.join(DATA_DIR, \"train\", data_file) )\n",
    "\n",
    "target_attr = \"Bankrupt\"\n",
    "\n",
    "n_samples, n_attrs = data.shape\n",
    "print(\"Date shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Have a look at the data\n",
    "\n",
    "We will not go through all steps in the Recipe, nor in depth.\n",
    "\n",
    "But here's a peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025417</td>\n",
       "      <td>0.41769</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>1.1605</td>\n",
       "      <td>-126.39</td>\n",
       "      <td>0.41355</td>\n",
       "      <td>0.025417</td>\n",
       "      <td>1.2395</td>\n",
       "      <td>1.16500</td>\n",
       "      <td>0.51773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049094</td>\n",
       "      <td>0.85835</td>\n",
       "      <td>0.12322</td>\n",
       "      <td>5.6167</td>\n",
       "      <td>7.4042</td>\n",
       "      <td>164.310</td>\n",
       "      <td>2.2214</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0</td>\n",
       "      <td>4510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.023834</td>\n",
       "      <td>0.2101</td>\n",
       "      <td>0.50839</td>\n",
       "      <td>4.2374</td>\n",
       "      <td>22.034</td>\n",
       "      <td>0.058412</td>\n",
       "      <td>-0.027621</td>\n",
       "      <td>3.6579</td>\n",
       "      <td>0.98183</td>\n",
       "      <td>0.76855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031011</td>\n",
       "      <td>1.01850</td>\n",
       "      <td>0.069047</td>\n",
       "      <td>5.7996</td>\n",
       "      <td>7.7529</td>\n",
       "      <td>26.446</td>\n",
       "      <td>13.802</td>\n",
       "      <td>6.4782</td>\n",
       "      <td>0</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030515</td>\n",
       "      <td>0.44606</td>\n",
       "      <td>0.19569</td>\n",
       "      <td>1.565</td>\n",
       "      <td>35.766</td>\n",
       "      <td>0.28196</td>\n",
       "      <td>0.039264</td>\n",
       "      <td>0.88456</td>\n",
       "      <td>1.05260</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077337</td>\n",
       "      <td>0.95006</td>\n",
       "      <td>0.25266</td>\n",
       "      <td>15.049</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>104.730</td>\n",
       "      <td>3.4852</td>\n",
       "      <td>2.6361</td>\n",
       "      <td>0</td>\n",
       "      <td>3920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.056366</td>\n",
       "      <td>0.54562</td>\n",
       "      <td>10.68</td>\n",
       "      <td>438.2</td>\n",
       "      <td>0.13649</td>\n",
       "      <td>0.058164</td>\n",
       "      <td>10.853</td>\n",
       "      <td>1.02790</td>\n",
       "      <td>0.61173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085524</td>\n",
       "      <td>0.97282</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0157</td>\n",
       "      <td>7.4626</td>\n",
       "      <td>48.756</td>\n",
       "      <td>7.4863</td>\n",
       "      <td>1.0602</td>\n",
       "      <td>0</td>\n",
       "      <td>1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.49712</td>\n",
       "      <td>0.12316</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>-71.398</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0116</td>\n",
       "      <td>1.29210</td>\n",
       "      <td>0.50288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.99925</td>\n",
       "      <td>0.019736</td>\n",
       "      <td>3.4819</td>\n",
       "      <td>8.582</td>\n",
       "      <td>114.580</td>\n",
       "      <td>3.1854</td>\n",
       "      <td>2.742</td>\n",
       "      <td>0</td>\n",
       "      <td>1529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2       X3      X4       X5        X6         X7  \\\n",
       "0   0.025417   0.41769   0.0568  1.1605  -126.39   0.41355   0.025417   \n",
       "1  -0.023834    0.2101  0.50839  4.2374   22.034  0.058412  -0.027621   \n",
       "2   0.030515   0.44606  0.19569   1.565   35.766   0.28196   0.039264   \n",
       "3   0.052318  0.056366  0.54562   10.68    438.2   0.13649   0.058164   \n",
       "4   0.000992   0.49712  0.12316  1.3036  -71.398         0   0.001007   \n",
       "\n",
       "        X8       X9      X10  ...        X57      X58       X59     X60  \\\n",
       "0   1.2395  1.16500  0.51773  ...   0.049094  0.85835   0.12322  5.6167   \n",
       "1   3.6579  0.98183  0.76855  ...  -0.031011  1.01850  0.069047  5.7996   \n",
       "2  0.88456  1.05260  0.39457  ...   0.077337  0.95006   0.25266  15.049   \n",
       "3   10.853  1.02790  0.61173  ...   0.085524  0.97282         0  6.0157   \n",
       "4   1.0116  1.29210  0.50288  ...   0.001974  0.99925  0.019736  3.4819   \n",
       "\n",
       "      X61      X62     X63     X64  Bankrupt    Id  \n",
       "0  7.4042  164.310  2.2214   1.334         0  4510  \n",
       "1  7.7529   26.446  13.802  6.4782         0  3537  \n",
       "2  2.8179  104.730  3.4852  2.6361         0  3920  \n",
       "3  7.4626   48.756  7.4863  1.0602         0  1806  \n",
       "4   8.582  114.580  3.1854   2.742         0  1529  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty *unhelpful* !\n",
    "\n",
    "What are these mysteriously named features ?\n",
    "\n",
    "## Description of attributes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "Id Company Identifier \n",
    "X1 net profit / total assets\n",
    "X2 total liabilities / total assets\n",
    "X3 working capital / total assets\n",
    "X4 current assets / short-term liabilities\n",
    "X5 [(cash + short-term securities + receivables - short-term liabilities) / (operating expenses - depreciation)] * 365\n",
    "X6 retained earnings / total assets\n",
    "X7 EBIT / total assets\n",
    "X8 book value of equity / total liabilities\n",
    "X9 sales / total assets\n",
    "X10 equity / total assets\n",
    "X11 (gross profit + extraordinary items + financial expenses) / total assets\n",
    "X12 gross profit / short-term liabilities\n",
    "X13 (gross profit + depreciation) / sales\n",
    "X14 (gross profit + interest) / total assets\n",
    "X15 (total liabilities * 365) / (gross profit + depreciation)\n",
    "X16 (gross profit + depreciation) / total liabilities\n",
    "X17 total assets / total liabilities\n",
    "X18 gross profit / total assets\n",
    "X19 gross profit / sales\n",
    "X20 (inventory * 365) / sales\n",
    "X21 sales (n) / sales (n-1)\n",
    "X22 profit on operating activities / total assets\n",
    "X23 net profit / sales\n",
    "X24 gross profit (in 3 years) / total assets\n",
    "X25 (equity - share capital) / total assets\n",
    "X26 (net profit + depreciation) / total liabilities\n",
    "X27 profit on operating activities / financial expenses\n",
    "X28 working capital / fixed assets\n",
    "X29 logarithm of total assets\n",
    "X30 (total liabilities - cash) / sales\n",
    "X31 (gross profit + interest) / sales\n",
    "X32 (current liabilities * 365) / cost of products sold\n",
    "X33 operating expenses / short-term liabilities\n",
    "X34 operating expenses / total liabilities\n",
    "X35 profit on sales / total assets\n",
    "X36 total sales / total assets\n",
    "X37 (current assets - inventories) / long-term liabilities\n",
    "X38 constant capital / total assets\n",
    "X39 profit on sales / sales\n",
    "X40 (current assets - inventory - receivables) / short-term liabilities\n",
    "X41 total liabilities / ((profit on operating activities + depreciation) * (12/365))\n",
    "X42 profit on operating activities / sales\n",
    "X43 rotation receivables + inventory turnover in days\n",
    "X44 (receivables * 365) / sales\n",
    "X45 net profit / inventory\n",
    "X46 (current assets - inventory) / short-term liabilities\n",
    "X47 (inventory * 365) / cost of products sold\n",
    "X48 EBITDA (profit on operating activities - depreciation) / total assets\n",
    "X49 EBITDA (profit on operating activities - depreciation) / sales\n",
    "X50 current assets / total liabilities\n",
    "X51 short-term liabilities / total assets\n",
    "X52 (short-term liabilities * 365) / cost of products sold)\n",
    "X53 equity / fixed assets\n",
    "X54 constant capital / fixed assets\n",
    "X55 working capital\n",
    "X56 (sales - cost of products sold) / sales\n",
    "X57 (current assets - inventory - short-term liabilities) / (sales - gross profit - depreciation)\n",
    "X58 total costs /total sales\n",
    "X59 long-term liabilities / equity\n",
    "X60 sales / inventory\n",
    "X61 sales / receivables\n",
    "X62 (short-term liabilities *365) / sales\n",
    "X63 sales / short-term liabilities\n",
    "X64 sales / fixed assets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may still be somewhat unhelpful for those of you not used to reading Financial Statements.\n",
    "\n",
    "But that's partially the point of the exercise\n",
    "- You can *still* perform Machine Learning *even if* you are not an expert in the problem domain\n",
    "    - That's what makes this a good interview exercise: you can demonstrate your thought process even if you don't know the exact meaning of the terms\n",
    "- Of course: becoming an expert in the domain *will improve* your ability to create better models\n",
    "    - Feature engineering is easier if you understand the features, their inter-relationships, and the relationship to the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a feel for the data\n",
    "- What is the type of each attribute ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4818 entries, 0 to 4817\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4818 non-null   object \n",
      " 1   X2        4818 non-null   object \n",
      " 2   X3        4818 non-null   object \n",
      " 3   X4        4818 non-null   object \n",
      " 4   X5        4818 non-null   object \n",
      " 5   X6        4818 non-null   object \n",
      " 6   X7        4818 non-null   object \n",
      " 7   X8        4818 non-null   object \n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4818 non-null   object \n",
      " 10  X11       4818 non-null   object \n",
      " 11  X12       4818 non-null   object \n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4818 non-null   object \n",
      " 14  X15       4818 non-null   object \n",
      " 15  X16       4818 non-null   object \n",
      " 16  X17       4818 non-null   object \n",
      " 17  X18       4818 non-null   object \n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4818 non-null   object \n",
      " 21  X22       4818 non-null   object \n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4818 non-null   object \n",
      " 24  X25       4818 non-null   object \n",
      " 25  X26       4818 non-null   object \n",
      " 26  X27       4818 non-null   object \n",
      " 27  X28       4818 non-null   object \n",
      " 28  X29       4818 non-null   object \n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4818 non-null   object \n",
      " 32  X33       4818 non-null   object \n",
      " 33  X34       4818 non-null   object \n",
      " 34  X35       4818 non-null   object \n",
      " 35  X36       4818 non-null   object \n",
      " 36  X37       4818 non-null   object \n",
      " 37  X38       4818 non-null   object \n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4818 non-null   object \n",
      " 40  X41       4818 non-null   object \n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4818 non-null   object \n",
      " 45  X46       4818 non-null   object \n",
      " 46  X47       4818 non-null   object \n",
      " 47  X48       4818 non-null   object \n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4818 non-null   object \n",
      " 50  X51       4818 non-null   object \n",
      " 51  X52       4818 non-null   object \n",
      " 52  X53       4818 non-null   object \n",
      " 53  X54       4818 non-null   object \n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4818 non-null   object \n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4818 non-null   object \n",
      " 59  X60       4818 non-null   object \n",
      " 60  X61       4818 non-null   object \n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4818 non-null   object \n",
      " 63  X64       4818 non-null   object \n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float64(16), int64(2), object(48)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may be puzzled:\n",
    "- Most attributes are `object` and *not* numeric (`float64`)\n",
    "- But looking at the data via `data.head()` certainly gives the impression that all attributes are numeric\n",
    "\n",
    "Welcome to the world of messy data !  The dataset has represented numbers as strings.\n",
    "- These little unexpected challenges are common in the real-word\n",
    "- Data is rarely perfect and clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you might want to first convert all attributes to numeric\n",
    "\n",
    "**Hint**\n",
    "- Look up the Pandas method `to_numeric`\n",
    "    - We suggest you use the option `errors='coerce'`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I do not know if the bakrupt/not_bankropt is randomlly distributed or not, I want to first to reorder the data in random order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sklearn.utils.shuffle(data, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will drop the ID column because it is completely not relevant to bankrupt ornot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop([\"Id\"], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transfer all datatype to float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.apply(pd.to_numeric, errors = 'coerce')\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4818 entries, 4340 to 860\n",
      "Data columns (total 66 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   X1        4816 non-null   float64\n",
      " 1   X2        4816 non-null   float64\n",
      " 2   X3        4816 non-null   float64\n",
      " 3   X4        4803 non-null   float64\n",
      " 4   X5        4808 non-null   float64\n",
      " 5   X6        4816 non-null   float64\n",
      " 6   X7        4816 non-null   float64\n",
      " 7   X8        4804 non-null   float64\n",
      " 8   X9        4818 non-null   float64\n",
      " 9   X10       4816 non-null   float64\n",
      " 10  X11       4816 non-null   float64\n",
      " 11  X12       4803 non-null   float64\n",
      " 12  X13       4818 non-null   float64\n",
      " 13  X14       4816 non-null   float64\n",
      " 14  X15       4812 non-null   float64\n",
      " 15  X16       4804 non-null   float64\n",
      " 16  X17       4804 non-null   float64\n",
      " 17  X18       4816 non-null   float64\n",
      " 18  X19       4818 non-null   float64\n",
      " 19  X20       4818 non-null   float64\n",
      " 20  X21       4744 non-null   float64\n",
      " 21  X22       4816 non-null   float64\n",
      " 22  X23       4818 non-null   float64\n",
      " 23  X24       4702 non-null   float64\n",
      " 24  X25       4816 non-null   float64\n",
      " 25  X26       4804 non-null   float64\n",
      " 26  X27       4513 non-null   float64\n",
      " 27  X28       4735 non-null   float64\n",
      " 28  X29       4816 non-null   float64\n",
      " 29  X30       4818 non-null   float64\n",
      " 30  X31       4818 non-null   float64\n",
      " 31  X32       4776 non-null   float64\n",
      " 32  X33       4803 non-null   float64\n",
      " 33  X34       4804 non-null   float64\n",
      " 34  X35       4816 non-null   float64\n",
      " 35  X36       4816 non-null   float64\n",
      " 36  X37       2750 non-null   float64\n",
      " 37  X38       4816 non-null   float64\n",
      " 38  X39       4818 non-null   float64\n",
      " 39  X40       4803 non-null   float64\n",
      " 40  X41       4756 non-null   float64\n",
      " 41  X42       4818 non-null   float64\n",
      " 42  X43       4818 non-null   float64\n",
      " 43  X44       4818 non-null   float64\n",
      " 44  X45       4598 non-null   float64\n",
      " 45  X46       4803 non-null   float64\n",
      " 46  X47       4787 non-null   float64\n",
      " 47  X48       4816 non-null   float64\n",
      " 48  X49       4818 non-null   float64\n",
      " 49  X50       4804 non-null   float64\n",
      " 50  X51       4816 non-null   float64\n",
      " 51  X52       4786 non-null   float64\n",
      " 52  X53       4735 non-null   float64\n",
      " 53  X54       4735 non-null   float64\n",
      " 54  X55       4818 non-null   float64\n",
      " 55  X56       4818 non-null   float64\n",
      " 56  X57       4816 non-null   float64\n",
      " 57  X58       4818 non-null   float64\n",
      " 58  X59       4816 non-null   float64\n",
      " 59  X60       4598 non-null   float64\n",
      " 60  X61       4806 non-null   float64\n",
      " 61  X62       4818 non-null   float64\n",
      " 62  X63       4803 non-null   float64\n",
      " 63  X64       4735 non-null   float64\n",
      " 64  Bankrupt  4818 non-null   int64  \n",
      " 65  Id        4818 non-null   int64  \n",
      "dtypes: float64(64), int64(2)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now split the data set to train_set and test_set use train_test_split, I also drop the id clumn as it is completely not relevant to bankrupt or not.\n",
    "I use median to fill all missing data because it not as sensitive to extreme value as average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.52630</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>0.89429</td>\n",
       "      <td>-88.844</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.88923</td>\n",
       "      <td>1.24840</td>\n",
       "      <td>0.46800</td>\n",
       "      <td>...</td>\n",
       "      <td>-13975.00</td>\n",
       "      <td>0.199000</td>\n",
       "      <td>0.041054</td>\n",
       "      <td>0.80100</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>7.2844</td>\n",
       "      <td>11.5030</td>\n",
       "      <td>107.0900</td>\n",
       "      <td>3.40820</td>\n",
       "      <td>0.556780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>0.160410</td>\n",
       "      <td>0.69907</td>\n",
       "      <td>0.090965</td>\n",
       "      <td>1.13010</td>\n",
       "      <td>10.146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198730</td>\n",
       "      <td>0.43047</td>\n",
       "      <td>3.44550</td>\n",
       "      <td>0.30093</td>\n",
       "      <td>...</td>\n",
       "      <td>134.00</td>\n",
       "      <td>0.055834</td>\n",
       "      <td>0.533050</td>\n",
       "      <td>0.94243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5676</td>\n",
       "      <td>74.0570</td>\n",
       "      <td>4.92870</td>\n",
       "      <td>16.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>0.089987</td>\n",
       "      <td>0.56987</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>6.35790</td>\n",
       "      <td>54.840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100760</td>\n",
       "      <td>0.75477</td>\n",
       "      <td>0.78787</td>\n",
       "      <td>0.43012</td>\n",
       "      <td>...</td>\n",
       "      <td>745.54</td>\n",
       "      <td>0.104040</td>\n",
       "      <td>0.209210</td>\n",
       "      <td>0.88032</td>\n",
       "      <td>1.279100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9970</td>\n",
       "      <td>8.4604</td>\n",
       "      <td>43.14200</td>\n",
       "      <td>0.891360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.48070</td>\n",
       "      <td>0.332930</td>\n",
       "      <td>1.74460</td>\n",
       "      <td>-82.067</td>\n",
       "      <td>0.028042</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>1.08030</td>\n",
       "      <td>1.21650</td>\n",
       "      <td>0.51930</td>\n",
       "      <td>...</td>\n",
       "      <td>3098.00</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>2.0511</td>\n",
       "      <td>7.7519</td>\n",
       "      <td>134.1600</td>\n",
       "      <td>2.72070</td>\n",
       "      <td>5.530400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>0.165180</td>\n",
       "      <td>0.20127</td>\n",
       "      <td>0.781430</td>\n",
       "      <td>4.88250</td>\n",
       "      <td>52.287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204360</td>\n",
       "      <td>3.96850</td>\n",
       "      <td>1.31190</td>\n",
       "      <td>0.79873</td>\n",
       "      <td>...</td>\n",
       "      <td>3739.00</td>\n",
       "      <td>0.163830</td>\n",
       "      <td>0.206810</td>\n",
       "      <td>0.84584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.1170</td>\n",
       "      <td>3.7472</td>\n",
       "      <td>56.0000</td>\n",
       "      <td>6.51790</td>\n",
       "      <td>75.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.27122</td>\n",
       "      <td>0.546070</td>\n",
       "      <td>3.01340</td>\n",
       "      <td>78.472</td>\n",
       "      <td>0.388460</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>2.68700</td>\n",
       "      <td>2.88010</td>\n",
       "      <td>0.72878</td>\n",
       "      <td>...</td>\n",
       "      <td>651.31</td>\n",
       "      <td>0.136680</td>\n",
       "      <td>0.409450</td>\n",
       "      <td>0.87237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330.7100</td>\n",
       "      <td>6.7177</td>\n",
       "      <td>34.3730</td>\n",
       "      <td>10.61900</td>\n",
       "      <td>15.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>0.174440</td>\n",
       "      <td>0.54906</td>\n",
       "      <td>0.280100</td>\n",
       "      <td>1.55000</td>\n",
       "      <td>-10.833</td>\n",
       "      <td>0.602800</td>\n",
       "      <td>0.217750</td>\n",
       "      <td>0.82129</td>\n",
       "      <td>1.05060</td>\n",
       "      <td>0.45094</td>\n",
       "      <td>...</td>\n",
       "      <td>49626.00</td>\n",
       "      <td>0.048165</td>\n",
       "      <td>0.386840</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>0.088172</td>\n",
       "      <td>19.8080</td>\n",
       "      <td>9.8811</td>\n",
       "      <td>42.6080</td>\n",
       "      <td>8.56640</td>\n",
       "      <td>20.716000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>-0.130150</td>\n",
       "      <td>0.34488</td>\n",
       "      <td>-0.062240</td>\n",
       "      <td>0.31906</td>\n",
       "      <td>-265.850</td>\n",
       "      <td>-0.387750</td>\n",
       "      <td>-0.130150</td>\n",
       "      <td>1.16780</td>\n",
       "      <td>0.28446</td>\n",
       "      <td>0.40275</td>\n",
       "      <td>...</td>\n",
       "      <td>-71677.00</td>\n",
       "      <td>-2.515400</td>\n",
       "      <td>-0.323150</td>\n",
       "      <td>3.51540</td>\n",
       "      <td>0.629350</td>\n",
       "      <td>23.5710</td>\n",
       "      <td>3.5718</td>\n",
       "      <td>720.7700</td>\n",
       "      <td>0.50641</td>\n",
       "      <td>0.047678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.50982</td>\n",
       "      <td>0.128820</td>\n",
       "      <td>1.43650</td>\n",
       "      <td>-46.091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058781</td>\n",
       "      <td>0.96148</td>\n",
       "      <td>1.06330</td>\n",
       "      <td>0.49018</td>\n",
       "      <td>...</td>\n",
       "      <td>667.55</td>\n",
       "      <td>0.053665</td>\n",
       "      <td>0.093114</td>\n",
       "      <td>0.94594</td>\n",
       "      <td>0.185170</td>\n",
       "      <td>4.3959</td>\n",
       "      <td>6.0577</td>\n",
       "      <td>101.3100</td>\n",
       "      <td>3.60270</td>\n",
       "      <td>1.846000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.22126</td>\n",
       "      <td>0.393340</td>\n",
       "      <td>2.77770</td>\n",
       "      <td>58.333</td>\n",
       "      <td>0.174590</td>\n",
       "      <td>0.143870</td>\n",
       "      <td>3.38930</td>\n",
       "      <td>1.00360</td>\n",
       "      <td>0.74991</td>\n",
       "      <td>...</td>\n",
       "      <td>15683.00</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.154680</td>\n",
       "      <td>0.99640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0714</td>\n",
       "      <td>4.2867</td>\n",
       "      <td>57.4420</td>\n",
       "      <td>6.35420</td>\n",
       "      <td>3.647800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3372 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1       X2        X3       X4       X5        X6        X7  \\\n",
       "109   0.019213  0.52630 -0.015068  0.89429  -88.844  0.019358  0.013060   \n",
       "1140  0.160410  0.69907  0.090965  1.13010   10.146  0.000000  0.198730   \n",
       "4399  0.089987  0.56987  0.097846  6.35790   54.840  0.000000  0.100760   \n",
       "4524  0.001961  0.48070  0.332930  1.74460  -82.067  0.028042  0.003307   \n",
       "2435  0.165180  0.20127  0.781430  4.88250   52.287  0.000000  0.204360   \n",
       "...        ...      ...       ...      ...      ...       ...       ...   \n",
       "4471  0.298400  0.27122  0.546070  3.01340   78.472  0.388460  0.368400   \n",
       "3095  0.174440  0.54906  0.280100  1.55000  -10.833  0.602800  0.217750   \n",
       "1367 -0.130150  0.34488 -0.062240  0.31906 -265.850 -0.387750 -0.130150   \n",
       "1724  0.045643  0.50982  0.128820  1.43650  -46.091  0.000000  0.058781   \n",
       "1038  0.116000  0.22126  0.393340  2.77770   58.333  0.174590  0.143870   \n",
       "\n",
       "           X8       X9      X10  ...       X55       X56       X57      X58  \\\n",
       "109   0.88923  1.24840  0.46800  ... -13975.00  0.199000  0.041054  0.80100   \n",
       "1140  0.43047  3.44550  0.30093  ...    134.00  0.055834  0.533050  0.94243   \n",
       "4399  0.75477  0.78787  0.43012  ...    745.54  0.104040  0.209210  0.88032   \n",
       "4524  1.08030  1.21650  0.51930  ...   3098.00  0.020703  0.003776  0.99730   \n",
       "2435  3.96850  1.31190  0.79873  ...   3739.00  0.163830  0.206810  0.84584   \n",
       "...       ...      ...      ...  ...       ...       ...       ...      ...   \n",
       "4471  2.68700  2.88010  0.72878  ...    651.31  0.136680  0.409450  0.87237   \n",
       "3095  0.82129  1.05060  0.45094  ...  49626.00  0.048165  0.386840  0.95183   \n",
       "1367  1.16780  0.28446  0.40275  ... -71677.00 -2.515400 -0.323150  3.51540   \n",
       "1724  0.96148  1.06330  0.49018  ...    667.55  0.053665  0.093114  0.94594   \n",
       "1038  3.38930  1.00360  0.74991  ...  15683.00  0.003595  0.154680  0.99640   \n",
       "\n",
       "           X59       X60      X61       X62       X63        X64  \n",
       "109   0.820000    7.2844  11.5030  107.0900   3.40820   0.556780  \n",
       "1140  0.000000       NaN   4.5676   74.0570   4.92870  16.410000  \n",
       "4399  1.279100       NaN   7.9970    8.4604  43.14200   0.891360  \n",
       "4524  0.046356    2.0511   7.7519  134.1600   2.72070   5.530400  \n",
       "2435  0.000000    2.1170   3.7472   56.0000   6.51790  75.829000  \n",
       "...        ...       ...      ...       ...       ...        ...  \n",
       "4471  0.000000  330.7100   6.7177   34.3730  10.61900  15.763000  \n",
       "3095  0.088172   19.8080   9.8811   42.6080   8.56640  20.716000  \n",
       "1367  0.629350   23.5710   3.5718  720.7700   0.50641   0.047678  \n",
       "1724  0.185170    4.3959   6.0577  101.3100   3.60270   1.846000  \n",
       "1038  0.000000    8.0714   4.2867   57.4420   6.35420   3.647800  \n",
       "\n",
       "[3372 rows x 64 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "traindata, testdata = train_test_split(data, test_size=0.3, random_state=42)\n",
    "X_train, y_train = traindata.drop(columns=[\"Bankrupt\",\"Id\"] ), traindata[ [\"Bankrupt\"] ]\n",
    "X_test, y_test = testdata.drop(columns=[\"Bankrupt\"] ), testdata[ [\"Bankrupt\"] ]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating your project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your submission on a test dataset that we provide\n",
    "- It has no labels, so **you** can't use it to evaluate your model, but **we** have the labels\n",
    "- We will call this evaluation dataset the \"holdout\" data\n",
    "\n",
    "Let's get it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (1092, 65)\n"
     ]
    }
   ],
   "source": [
    "holdout_data = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "print(\"Data shape: \", holdout_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your model on the holdout examples using metrics\n",
    "- Accuracy\n",
    "- Recall\n",
    "- Precision\n",
    "\n",
    "From our lecture: we may have to make a trade-off between Recall and Precision.\n",
    "\n",
    "Our evaluation of your submission will be partially based on how you made (and described) the trade-off.\n",
    "\n",
    "You may assume that it is 5 times worse to *fail to identify a company that will go bankrupt*\n",
    "than it is to fail to identify a company that won't go bankrupt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your model\n",
    "\n",
    "Time for you to continue the Recipe for Machine Learning on your own.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import decomposition\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try several models in this project including SVC, Decision Tree, and Logistic Regression.\n",
    "I apply GridSearchCV to tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I apply some data transform: StandardScaler and SimpleImputer. \n",
    "It will be applied in all pipelines for different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy = 'median')\n",
    "scaler = StandardScaler()\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "DT = DecisionTreeClassifier(random_state = 42)\n",
    "pipe_DT = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                          ('model', DT)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_DT = {'model__max_features': [2,4,7,10,15,20,30,50],\n",
    "              'model__criterion': ['gini', 'entropy'],\n",
    "                'model__max_depth' : [2,4,7,10,15,20,30,50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('imputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model',\n",
       "                                        DecisionTreeClassifier(random_state=42))]),\n",
       "             param_grid={'model__criterion': ['gini', 'entropy'],\n",
       "                         'model__max_depth': [2, 4, 7, 10, 15, 20, 30, 50],\n",
       "                         'model__max_features': [2, 4, 7, 10, 15, 20, 30, 50]})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__criterion': 'gini', 'model__max_depth': 2, 'model__max_features': 4}\n"
     ]
    }
   ],
   "source": [
    "grid_DT = GridSearchCV(pipe_DT, param_grid_DT)\n",
    "grid_DT.fit(X_train, y_train)\n",
    "print(grid_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 DecisionTreeClassifier(max_depth=2, max_features=4,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model in_samle_score is:  0.9383155397390273\n"
     ]
    }
   ],
   "source": [
    "optimal_DT = DecisionTreeClassifier(criterion = \"gini\", random_state = 42,\n",
    "                           max_depth = 2,\n",
    "                           max_features = 4)\n",
    "pipe_DT = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                           ('model', optimal_DT)])\n",
    "pipe_DT.fit(X_train,y_train)\n",
    "y_pred = pipe_DT.predict(X_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Decision Tree Model in_samle_score is: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('imputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model', LogisticRegression())]),\n",
       "             param_grid={'model__C': [1e-05, 0.001, 0.1, 1, 10, 50, 100],\n",
       "                         'model__penalty': ('l1', 'l2', 'elasticnet')})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 0.001, 'model__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()\n",
    "param_grid_LR = {'model__C': [0.00001,0.001,0.1,1,10, 50, 100],\n",
    "             'model__penalty':('l1', 'l2', 'elasticnet')}\n",
    "pipe_LR = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                           ('model', LR)])\n",
    "grid_LR = GridSearchCV(pipe_LR, param_grid_LR)\n",
    "grid_LR.fit(X_train, y_train)\n",
    "print(grid_LR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('model', LogisticRegression(C=0.001))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model in_samle_score is:  0.9350533807829181\n"
     ]
    }
   ],
   "source": [
    "optimal_LR = LogisticRegression(C=0.001,penalty='l2')\n",
    "pipe_LR = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                           ('model', optimal_LR)])\n",
    "pipe_LR.fit(X_train,y_train)\n",
    "y_pred = pipe_LR.predict(X_train)\n",
    "print(\"Logistic Regression Model in_samle_score is: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('imputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('model', SVC())]),\n",
       "             param_grid={'model__C': [0.1, 1, 5],\n",
       "                         'model__gamma': [0.001, 0.05, 0.01, 0.5, 1]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 1, 'model__gamma': 0.5}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf')\n",
    "pipe_svc = Pipeline(steps=[('scaler', scaler),('imputer', imp),\n",
    "                           ('model', svc)])\n",
    "param_grid_svc = {'model__C': [ 0.1, 1,5],\n",
    "              'model__gamma': [0.001,0.05, 0.01, 0.5,1]}\n",
    "\n",
    "grid_svc = GridSearchCV(pipe_svc, param_grid_svc)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print(grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()), ('model', SVC(C=1, gamma=0.5))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Model in_samle_score is:  0.9620403321470937\n"
     ]
    }
   ],
   "source": [
    "optimal_svc = SVC(kernel='rbf',C=1,gamma=0.5)\n",
    "pipe_svc = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                           ('model', optimal_svc)])\n",
    "pipe_svc.fit(X_train,y_train)\n",
    "y_pred = pipe_svc.predict(X_train)\n",
    "print(\"SVC Model in_samle_score is: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis and Recall_precission trade off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a look at the cross validation score for this three model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Model: avg cross validation score=0.94\n",
      "\n",
      "Logistic Regression Model: avg cross validation score=0.94\n",
      "\n",
      "SVC Model: avg cross validation score=0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = cross_val_score(pipe_DT, X_train, y_train, cv=5)\n",
    "print(\"{m:s} Model: avg cross validation score={s:3.2f}\\n\".format(m=\"Decission Tree\", s=cross_val_scores.mean()) )\n",
    "cross_val_scores = cross_val_score(pipe_LR, X_train, y_train, cv=5)\n",
    "print(\"{m:s} Model: avg cross validation score={s:3.2f}\\n\".format(m=\"Logistic Regression\", s=cross_val_scores.mean()) )\n",
    "cross_val_scores = cross_val_score(pipe_svc, X_train, y_train, cv=5)\n",
    "print(\"{m:s} Model: avg cross validation score={s:3.2f}\\n\".format(m=\"SVC\", s=cross_val_scores.mean()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the f1 score to see the recall_precission situation\n",
    "Where f1 score range from 0 to 1, 1 is the best and 0 is generally the worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Model: f1 score=0.15\n",
      "\n",
      "Logistic Regression Model: f1 score=0.02\n",
      "\n",
      "SVC Model: f1 score=0.59\n",
      "\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.metrics import f1_score\n",
    "y_DT=pipe_DT.predict(X_train)\n",
    "y_LR=pipe_LR.predict(X_train)\n",
    "y_svc=pipe_svc.predict(X_train)\n",
    "print(\"{m:s} Model: f1 score={s:3.2f}\\n\".format(m=\"Decission Tree\", s=f1_score(y_train, y_DT) ) )\n",
    "print(\"{m:s} Model: f1 score={s:3.2f}\\n\".format(m=\"Logistic Regression\", s=f1_score(y_train, y_LR)) )\n",
    "print(\"{m:s} Model: f1 score={s:3.2f}\\n\".format(m=\"SVC\", s=f1_score(y_train, y_svc)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Logistic regression model have very poor recall_precission tradeoff, other two models are also not optimal.\n",
    "let's take a look at the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bankrupt    0.065243\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This actually tell us that in our training model, ony 6.5% of cases go to bankrupt, this data is highly unbalanced and we may able to improve the recall_precissiom by balance the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With balanced data, the more case of bankrupt involved, our may be able to identified the bankrupt more accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving our model base on the error analysis and the recall_precission tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we resample the data to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.52630</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>0.89429</td>\n",
       "      <td>-88.844</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.88923</td>\n",
       "      <td>1.24840</td>\n",
       "      <td>0.46800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041054</td>\n",
       "      <td>0.80100</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>7.2844</td>\n",
       "      <td>11.5030</td>\n",
       "      <td>107.0900</td>\n",
       "      <td>3.40820</td>\n",
       "      <td>0.556780</td>\n",
       "      <td>0</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>0.160410</td>\n",
       "      <td>0.69907</td>\n",
       "      <td>0.090965</td>\n",
       "      <td>1.13010</td>\n",
       "      <td>10.146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198730</td>\n",
       "      <td>0.43047</td>\n",
       "      <td>3.44550</td>\n",
       "      <td>0.30093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533050</td>\n",
       "      <td>0.94243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5676</td>\n",
       "      <td>74.0570</td>\n",
       "      <td>4.92870</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>0</td>\n",
       "      <td>4798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>0.089987</td>\n",
       "      <td>0.56987</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>6.35790</td>\n",
       "      <td>54.840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100760</td>\n",
       "      <td>0.75477</td>\n",
       "      <td>0.78787</td>\n",
       "      <td>0.43012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209210</td>\n",
       "      <td>0.88032</td>\n",
       "      <td>1.279100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.9970</td>\n",
       "      <td>8.4604</td>\n",
       "      <td>43.14200</td>\n",
       "      <td>0.891360</td>\n",
       "      <td>0</td>\n",
       "      <td>2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.48070</td>\n",
       "      <td>0.332930</td>\n",
       "      <td>1.74460</td>\n",
       "      <td>-82.067</td>\n",
       "      <td>0.028042</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>1.08030</td>\n",
       "      <td>1.21650</td>\n",
       "      <td>0.51930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>2.0511</td>\n",
       "      <td>7.7519</td>\n",
       "      <td>134.1600</td>\n",
       "      <td>2.72070</td>\n",
       "      <td>5.530400</td>\n",
       "      <td>0</td>\n",
       "      <td>3872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>0.165180</td>\n",
       "      <td>0.20127</td>\n",
       "      <td>0.781430</td>\n",
       "      <td>4.88250</td>\n",
       "      <td>52.287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204360</td>\n",
       "      <td>3.96850</td>\n",
       "      <td>1.31190</td>\n",
       "      <td>0.79873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206810</td>\n",
       "      <td>0.84584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.1170</td>\n",
       "      <td>3.7472</td>\n",
       "      <td>56.0000</td>\n",
       "      <td>6.51790</td>\n",
       "      <td>75.829000</td>\n",
       "      <td>0</td>\n",
       "      <td>1711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4471</th>\n",
       "      <td>0.298400</td>\n",
       "      <td>0.27122</td>\n",
       "      <td>0.546070</td>\n",
       "      <td>3.01340</td>\n",
       "      <td>78.472</td>\n",
       "      <td>0.388460</td>\n",
       "      <td>0.368400</td>\n",
       "      <td>2.68700</td>\n",
       "      <td>2.88010</td>\n",
       "      <td>0.72878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409450</td>\n",
       "      <td>0.87237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>330.7100</td>\n",
       "      <td>6.7177</td>\n",
       "      <td>34.3730</td>\n",
       "      <td>10.61900</td>\n",
       "      <td>15.763000</td>\n",
       "      <td>0</td>\n",
       "      <td>5569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>0.174440</td>\n",
       "      <td>0.54906</td>\n",
       "      <td>0.280100</td>\n",
       "      <td>1.55000</td>\n",
       "      <td>-10.833</td>\n",
       "      <td>0.602800</td>\n",
       "      <td>0.217750</td>\n",
       "      <td>0.82129</td>\n",
       "      <td>1.05060</td>\n",
       "      <td>0.45094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386840</td>\n",
       "      <td>0.95183</td>\n",
       "      <td>0.088172</td>\n",
       "      <td>19.8080</td>\n",
       "      <td>9.8811</td>\n",
       "      <td>42.6080</td>\n",
       "      <td>8.56640</td>\n",
       "      <td>20.716000</td>\n",
       "      <td>0</td>\n",
       "      <td>1822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>-0.130150</td>\n",
       "      <td>0.34488</td>\n",
       "      <td>-0.062240</td>\n",
       "      <td>0.31906</td>\n",
       "      <td>-265.850</td>\n",
       "      <td>-0.387750</td>\n",
       "      <td>-0.130150</td>\n",
       "      <td>1.16780</td>\n",
       "      <td>0.28446</td>\n",
       "      <td>0.40275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.323150</td>\n",
       "      <td>3.51540</td>\n",
       "      <td>0.629350</td>\n",
       "      <td>23.5710</td>\n",
       "      <td>3.5718</td>\n",
       "      <td>720.7700</td>\n",
       "      <td>0.50641</td>\n",
       "      <td>0.047678</td>\n",
       "      <td>0</td>\n",
       "      <td>5388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>0.045643</td>\n",
       "      <td>0.50982</td>\n",
       "      <td>0.128820</td>\n",
       "      <td>1.43650</td>\n",
       "      <td>-46.091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058781</td>\n",
       "      <td>0.96148</td>\n",
       "      <td>1.06330</td>\n",
       "      <td>0.49018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093114</td>\n",
       "      <td>0.94594</td>\n",
       "      <td>0.185170</td>\n",
       "      <td>4.3959</td>\n",
       "      <td>6.0577</td>\n",
       "      <td>101.3100</td>\n",
       "      <td>3.60270</td>\n",
       "      <td>1.846000</td>\n",
       "      <td>0</td>\n",
       "      <td>2196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.22126</td>\n",
       "      <td>0.393340</td>\n",
       "      <td>2.77770</td>\n",
       "      <td>58.333</td>\n",
       "      <td>0.174590</td>\n",
       "      <td>0.143870</td>\n",
       "      <td>3.38930</td>\n",
       "      <td>1.00360</td>\n",
       "      <td>0.74991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154680</td>\n",
       "      <td>0.99640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0714</td>\n",
       "      <td>4.2867</td>\n",
       "      <td>57.4420</td>\n",
       "      <td>6.35420</td>\n",
       "      <td>3.647800</td>\n",
       "      <td>0</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3152 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1       X2        X3       X4       X5        X6        X7  \\\n",
       "109   0.019213  0.52630 -0.015068  0.89429  -88.844  0.019358  0.013060   \n",
       "1140  0.160410  0.69907  0.090965  1.13010   10.146  0.000000  0.198730   \n",
       "4399  0.089987  0.56987  0.097846  6.35790   54.840  0.000000  0.100760   \n",
       "4524  0.001961  0.48070  0.332930  1.74460  -82.067  0.028042  0.003307   \n",
       "2435  0.165180  0.20127  0.781430  4.88250   52.287  0.000000  0.204360   \n",
       "...        ...      ...       ...      ...      ...       ...       ...   \n",
       "4471  0.298400  0.27122  0.546070  3.01340   78.472  0.388460  0.368400   \n",
       "3095  0.174440  0.54906  0.280100  1.55000  -10.833  0.602800  0.217750   \n",
       "1367 -0.130150  0.34488 -0.062240  0.31906 -265.850 -0.387750 -0.130150   \n",
       "1724  0.045643  0.50982  0.128820  1.43650  -46.091  0.000000  0.058781   \n",
       "1038  0.116000  0.22126  0.393340  2.77770   58.333  0.174590  0.143870   \n",
       "\n",
       "           X8       X9      X10  ...       X57      X58       X59       X60  \\\n",
       "109   0.88923  1.24840  0.46800  ...  0.041054  0.80100  0.820000    7.2844   \n",
       "1140  0.43047  3.44550  0.30093  ...  0.533050  0.94243  0.000000       NaN   \n",
       "4399  0.75477  0.78787  0.43012  ...  0.209210  0.88032  1.279100       NaN   \n",
       "4524  1.08030  1.21650  0.51930  ...  0.003776  0.99730  0.046356    2.0511   \n",
       "2435  3.96850  1.31190  0.79873  ...  0.206810  0.84584  0.000000    2.1170   \n",
       "...       ...      ...      ...  ...       ...      ...       ...       ...   \n",
       "4471  2.68700  2.88010  0.72878  ...  0.409450  0.87237  0.000000  330.7100   \n",
       "3095  0.82129  1.05060  0.45094  ...  0.386840  0.95183  0.088172   19.8080   \n",
       "1367  1.16780  0.28446  0.40275  ... -0.323150  3.51540  0.629350   23.5710   \n",
       "1724  0.96148  1.06330  0.49018  ...  0.093114  0.94594  0.185170    4.3959   \n",
       "1038  3.38930  1.00360  0.74991  ...  0.154680  0.99640  0.000000    8.0714   \n",
       "\n",
       "          X61       X62       X63        X64  Bankrupt    Id  \n",
       "109   11.5030  107.0900   3.40820   0.556780         0  2917  \n",
       "1140   4.5676   74.0570   4.92870  16.410000         0  4798  \n",
       "4399   7.9970    8.4604  43.14200   0.891360         0  2904  \n",
       "4524   7.7519  134.1600   2.72070   5.530400         0  3872  \n",
       "2435   3.7472   56.0000   6.51790  75.829000         0  1711  \n",
       "...       ...       ...       ...        ...       ...   ...  \n",
       "4471   6.7177   34.3730  10.61900  15.763000         0  5569  \n",
       "3095   9.8811   42.6080   8.56640  20.716000         0  1822  \n",
       "1367   3.5718  720.7700   0.50641   0.047678         0  5388  \n",
       "1724   6.0577  101.3100   3.60270   1.846000         0  2196  \n",
       "1038   4.2867   57.4420   6.35420   3.647800         0  1209  \n",
       "\n",
       "[3152 rows x 66 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bankrupt_0 = traindata[traindata.Bankrupt==0]\n",
    "data_bankrupt_1 = traindata[traindata.Bankrupt==1]\n",
    "data_bankrupt_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the oversample to balance the data because if we do underfitting, there will be too little data to train.  \n",
    "we see there are 3152 cases not bankrupt, so we will also match 3152 case of bankrupt to balance our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "new_data_bankrupt = resample(data_bankrupt_1,replace = True, n_samples = 3152,random_state = 42)\n",
    "balanced_traindata = pd.concat([data_bankrupt_0, new_data_bankrupt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take a look at new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.019213</td>\n",
       "      <td>0.52630</td>\n",
       "      <td>-0.015068</td>\n",
       "      <td>0.89429</td>\n",
       "      <td>-88.8440</td>\n",
       "      <td>0.019358</td>\n",
       "      <td>0.013060</td>\n",
       "      <td>0.88923</td>\n",
       "      <td>1.248400</td>\n",
       "      <td>0.46800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041054</td>\n",
       "      <td>0.80100</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>7.2844</td>\n",
       "      <td>11.503000</td>\n",
       "      <td>107.0900</td>\n",
       "      <td>3.408200</td>\n",
       "      <td>0.556780</td>\n",
       "      <td>0</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>0.160410</td>\n",
       "      <td>0.69907</td>\n",
       "      <td>0.090965</td>\n",
       "      <td>1.13010</td>\n",
       "      <td>10.1460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.198730</td>\n",
       "      <td>0.43047</td>\n",
       "      <td>3.445500</td>\n",
       "      <td>0.30093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533050</td>\n",
       "      <td>0.94243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.567600</td>\n",
       "      <td>74.0570</td>\n",
       "      <td>4.928700</td>\n",
       "      <td>16.410000</td>\n",
       "      <td>0</td>\n",
       "      <td>4798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>0.089987</td>\n",
       "      <td>0.56987</td>\n",
       "      <td>0.097846</td>\n",
       "      <td>6.35790</td>\n",
       "      <td>54.8400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100760</td>\n",
       "      <td>0.75477</td>\n",
       "      <td>0.787870</td>\n",
       "      <td>0.43012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209210</td>\n",
       "      <td>0.88032</td>\n",
       "      <td>1.279100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.997000</td>\n",
       "      <td>8.4604</td>\n",
       "      <td>43.142000</td>\n",
       "      <td>0.891360</td>\n",
       "      <td>0</td>\n",
       "      <td>2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4524</th>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.48070</td>\n",
       "      <td>0.332930</td>\n",
       "      <td>1.74460</td>\n",
       "      <td>-82.0670</td>\n",
       "      <td>0.028042</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>1.08030</td>\n",
       "      <td>1.216500</td>\n",
       "      <td>0.51930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.99730</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>2.0511</td>\n",
       "      <td>7.751900</td>\n",
       "      <td>134.1600</td>\n",
       "      <td>2.720700</td>\n",
       "      <td>5.530400</td>\n",
       "      <td>0</td>\n",
       "      <td>3872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2435</th>\n",
       "      <td>0.165180</td>\n",
       "      <td>0.20127</td>\n",
       "      <td>0.781430</td>\n",
       "      <td>4.88250</td>\n",
       "      <td>52.2870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204360</td>\n",
       "      <td>3.96850</td>\n",
       "      <td>1.311900</td>\n",
       "      <td>0.79873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206810</td>\n",
       "      <td>0.84584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.1170</td>\n",
       "      <td>3.747200</td>\n",
       "      <td>56.0000</td>\n",
       "      <td>6.517900</td>\n",
       "      <td>75.829000</td>\n",
       "      <td>0</td>\n",
       "      <td>1711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>-0.507060</td>\n",
       "      <td>0.15578</td>\n",
       "      <td>0.594650</td>\n",
       "      <td>4.81740</td>\n",
       "      <td>45.5530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.507060</td>\n",
       "      <td>5.41940</td>\n",
       "      <td>2.088900</td>\n",
       "      <td>0.84420</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.600640</td>\n",
       "      <td>1.15750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.4940</td>\n",
       "      <td>5.294200</td>\n",
       "      <td>27.2190</td>\n",
       "      <td>13.410000</td>\n",
       "      <td>8.369900</td>\n",
       "      <td>1</td>\n",
       "      <td>5162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>-0.682290</td>\n",
       "      <td>4.77090</td>\n",
       "      <td>0.235260</td>\n",
       "      <td>1.64010</td>\n",
       "      <td>1032.2000</td>\n",
       "      <td>-3.277000</td>\n",
       "      <td>-0.682290</td>\n",
       "      <td>-0.79040</td>\n",
       "      <td>0.031879</td>\n",
       "      <td>-3.77090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.180940</td>\n",
       "      <td>22.40200</td>\n",
       "      <td>-1.167700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053105</td>\n",
       "      <td>4208.3000</td>\n",
       "      <td>0.086734</td>\n",
       "      <td>0.080263</td>\n",
       "      <td>1</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.69863</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>0.99768</td>\n",
       "      <td>-78.5210</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>0.007031</td>\n",
       "      <td>0.43138</td>\n",
       "      <td>1.304600</td>\n",
       "      <td>0.30137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013144</td>\n",
       "      <td>0.99506</td>\n",
       "      <td>0.522540</td>\n",
       "      <td>4.9624</td>\n",
       "      <td>8.207700</td>\n",
       "      <td>120.5800</td>\n",
       "      <td>3.027100</td>\n",
       "      <td>2.288600</td>\n",
       "      <td>1</td>\n",
       "      <td>4155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>-0.405880</td>\n",
       "      <td>2.15750</td>\n",
       "      <td>-1.576300</td>\n",
       "      <td>0.25320</td>\n",
       "      <td>-287.5200</td>\n",
       "      <td>-0.405880</td>\n",
       "      <td>-0.405880</td>\n",
       "      <td>-0.61162</td>\n",
       "      <td>0.872050</td>\n",
       "      <td>-1.31960</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307590</td>\n",
       "      <td>1.14670</td>\n",
       "      <td>-0.035435</td>\n",
       "      <td>9.1461</td>\n",
       "      <td>7.719200</td>\n",
       "      <td>371.9100</td>\n",
       "      <td>0.981410</td>\n",
       "      <td>4.449400</td>\n",
       "      <td>1</td>\n",
       "      <td>2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>0.194540</td>\n",
       "      <td>0.55830</td>\n",
       "      <td>0.281430</td>\n",
       "      <td>1.58800</td>\n",
       "      <td>5.1795</td>\n",
       "      <td>0.194540</td>\n",
       "      <td>0.242840</td>\n",
       "      <td>0.76759</td>\n",
       "      <td>1.056000</td>\n",
       "      <td>0.42855</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453940</td>\n",
       "      <td>0.94694</td>\n",
       "      <td>0.185940</td>\n",
       "      <td>20.2950</td>\n",
       "      <td>14.528000</td>\n",
       "      <td>39.3010</td>\n",
       "      <td>9.287300</td>\n",
       "      <td>18.525000</td>\n",
       "      <td>1</td>\n",
       "      <td>3669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6304 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1       X2        X3       X4         X5        X6        X7  \\\n",
       "109   0.019213  0.52630 -0.015068  0.89429   -88.8440  0.019358  0.013060   \n",
       "1140  0.160410  0.69907  0.090965  1.13010    10.1460  0.000000  0.198730   \n",
       "4399  0.089987  0.56987  0.097846  6.35790    54.8400  0.000000  0.100760   \n",
       "4524  0.001961  0.48070  0.332930  1.74460   -82.0670  0.028042  0.003307   \n",
       "2435  0.165180  0.20127  0.781430  4.88250    52.2870  0.000000  0.204360   \n",
       "...        ...      ...       ...      ...        ...       ...       ...   \n",
       "3090 -0.507060  0.15578  0.594650  4.81740    45.5530  0.000000 -0.507060   \n",
       "2154 -0.682290  4.77090  0.235260  1.64010  1032.2000 -3.277000 -0.682290   \n",
       "234   0.003961  0.69863 -0.000999  0.99768   -78.5210 -0.019608  0.007031   \n",
       "677  -0.405880  2.15750 -1.576300  0.25320  -287.5200 -0.405880 -0.405880   \n",
       "1126  0.194540  0.55830  0.281430  1.58800     5.1795  0.194540  0.242840   \n",
       "\n",
       "           X8        X9      X10  ...       X57       X58       X59      X60  \\\n",
       "109   0.88923  1.248400  0.46800  ...  0.041054   0.80100  0.820000   7.2844   \n",
       "1140  0.43047  3.445500  0.30093  ...  0.533050   0.94243  0.000000      NaN   \n",
       "4399  0.75477  0.787870  0.43012  ...  0.209210   0.88032  1.279100      NaN   \n",
       "4524  1.08030  1.216500  0.51930  ...  0.003776   0.99730  0.046356   2.0511   \n",
       "2435  3.96850  1.311900  0.79873  ...  0.206810   0.84584  0.000000   2.1170   \n",
       "...       ...       ...      ...  ...       ...       ...       ...      ...   \n",
       "3090  5.41940  2.088900  0.84420  ... -0.600640   1.15750  0.000000  16.4940   \n",
       "2154 -0.79040  0.031879 -3.77090  ...  0.180940  22.40200 -1.167700      NaN   \n",
       "234   0.43138  1.304600  0.30137  ...  0.013144   0.99506  0.522540   4.9624   \n",
       "677  -0.61162  0.872050 -1.31960  ...  0.307590   1.14670 -0.035435   9.1461   \n",
       "1126  0.76759  1.056000  0.42855  ...  0.453940   0.94694  0.185940  20.2950   \n",
       "\n",
       "            X61        X62        X63        X64  Bankrupt    Id  \n",
       "109   11.503000   107.0900   3.408200   0.556780         0  2917  \n",
       "1140   4.567600    74.0570   4.928700  16.410000         0  4798  \n",
       "4399   7.997000     8.4604  43.142000   0.891360         0  2904  \n",
       "4524   7.751900   134.1600   2.720700   5.530400         0  3872  \n",
       "2435   3.747200    56.0000   6.517900  75.829000         0  1711  \n",
       "...         ...        ...        ...        ...       ...   ...  \n",
       "3090   5.294200    27.2190  13.410000   8.369900         1  5162  \n",
       "2154   0.053105  4208.3000   0.086734   0.080263         1  1776  \n",
       "234    8.207700   120.5800   3.027100   2.288600         1  4155  \n",
       "677    7.719200   371.9100   0.981410   4.449400         1  2202  \n",
       "1126  14.528000    39.3010   9.287300  18.525000         1  3669  \n",
       "\n",
       "[6304 rows x 66 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_traindata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks good but all bankrupt case is at the end because the way we resample it, need to reorder to ramdom order\n",
    "we also need to confirmed that the % of bankrupts is about 50% in our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_traindata = sklearn.utils.shuffle(balanced_traindata, random_state = 42)\n",
    "balanced_traindata.Bankrupt.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now construct the X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = balanced_traindata.drop(columns=[\"Bankrupt\",\"Id\"] ), balanced_traindata[ [\"Bankrupt\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our training set have changed, we need to retest our models, tuning them and to see if the performance is improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('imputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('model', LogisticRegression())]),\n",
       "             param_grid={'model__C': [1e-05, 0.001, 0.1, 1, 10, 50, 100],\n",
       "                         'model__penalty': ('l1', 'l2', 'elasticnet')})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 10, 'model__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "param_grid_LR = {'model__C': [0.00001,0.001,0.1,1,10, 50, 100],\n",
    "             'model__penalty':('l1', 'l2', 'elasticnet')}\n",
    "pipe_LR = Pipeline(steps=[('scaler', scaler),('imputer', imp),\n",
    "                           ('model', LR)])\n",
    "grid_LR = GridSearchCV(pipe_LR, param_grid_LR)\n",
    "grid_LR.fit(X_train, y_train)\n",
    "print(grid_LR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('model', LogisticRegression(C=10))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model in_samle_score is:  0.7991751269035533\n"
     ]
    }
   ],
   "source": [
    "optimal_LR = LogisticRegression(C=10,penalty='l2')\n",
    "pipe_LR = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                           ('model', optimal_LR)])\n",
    "pipe_LR.fit(X_train,y_train)\n",
    "y_pred = pipe_LR.predict(X_train)\n",
    "print(\"Decision Tree Model in_samle_score is: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('imputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('model', SVC())]),\n",
       "             param_grid={'model__C': [0.1, 1, 5],\n",
       "                         'model__gamma': [0.01, 0.02, 0.05, 0.2, 1]})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 5, 'model__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "pipe_svc = Pipeline(steps=[('scaler', scaler),('imputer', imp),\n",
    "                           ('model', svc)])\n",
    "param_grid_svc = {'model__C': [ 0.1, 1 , 5],\n",
    "              'model__gamma': [0.01 ,0.02,0.05,0.2, 1 ]}\n",
    "\n",
    "grid_svc = GridSearchCV(pipe_svc, param_grid_svc)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print(grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()), ('model', SVC(C=5, gamma=1))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Model in_samle_score is:  0.9915926395939086\n"
     ]
    }
   ],
   "source": [
    "optimal_svc = SVC(kernel='rbf',C=5,gamma=1)\n",
    "pipe_svc = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                           ('model', optimal_svc)])\n",
    "pipe_svc.fit(X_train,y_train)\n",
    "y_pred = pipe_svc.predict(X_train)\n",
    "print(\"SVC Model in_samle_score is: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('imputer',\n",
       "                                        SimpleImputer(strategy='median')),\n",
       "                                       ('model',\n",
       "                                        DecisionTreeClassifier(random_state=42))]),\n",
       "             param_grid={'model__criterion': ['gini', 'entropy'],\n",
       "                         'model__max_depth': [2, 4, 7, 10, 15, 20, 30, 50],\n",
       "                         'model__max_features': [2, 4, 7, 10, 15, 20, 30, 50]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__criterion': 'gini', 'model__max_depth': 30, 'model__max_features': 30}\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier(random_state = 42)\n",
    "pipe_DT = Pipeline(steps=[('scaler', scaler),('imputer', imp),\n",
    "                          ('model', DT)])\n",
    "param_grid_DT = {'model__max_features': [2,4,7,10,15,20,30,50],\n",
    "              'model__criterion': ['gini', 'entropy'],\n",
    "                'model__max_depth' : [2,4,7,10,15,20,30,50]}\n",
    "grid_DT = GridSearchCV(pipe_DT, param_grid_DT)\n",
    "grid_DT.fit(X_train, y_train)\n",
    "print(grid_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 DecisionTreeClassifier(max_depth=30, max_features=30,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Model in_samle_score is:  0.9980964467005076\n"
     ]
    }
   ],
   "source": [
    "optimal_DT = DecisionTreeClassifier(criterion = \"gini\", random_state = 42,\n",
    "                           max_depth = 30,\n",
    "                           max_features = 30)\n",
    "pipe_DT = Pipeline(steps=[('imputer', imp),('scaler', scaler),\n",
    "                           ('model', optimal_DT)])\n",
    "pipe_DT.fit(X_train,y_train)\n",
    "y_pred = pipe_DT.predict(X_train)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Decision Tree Model in_samle_score is: \",accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at our models performance again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Model: avg cross validation score=0.98\n",
      "\n",
      "Logistic Regression Model: avg cross validation score=0.80\n",
      "\n",
      "SVC Model: avg cross validation score=0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_val_scores = cross_val_score(pipe_DT, X_train, y_train, cv=5)\n",
    "print(\"{m:s} Model: avg cross validation score={s:3.2f}\\n\".format(m=\"Decission Tree\", s=cross_val_scores.mean()) )\n",
    "cross_val_scores = cross_val_score(pipe_LR, X_train, y_train, cv=5)\n",
    "print(\"{m:s} Model: avg cross validation score={s:3.2f}\\n\".format(m=\"Logistic Regression\", s=cross_val_scores.mean()) )\n",
    "cross_val_scores = cross_val_score(pipe_svc, X_train, y_train, cv=5)\n",
    "print(\"{m:s} Model: avg cross validation score={s:3.2f}\\n\".format(m=\"SVC\", s=cross_val_scores.mean()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Model: f1 score=1.00\n",
      "\n",
      "Logistic Regression Model: f1 score=0.80\n",
      "\n",
      "SVC Model: f1 score=0.99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_DT=pipe_DT.predict(X_train)\n",
    "y_LR=pipe_LR.predict(X_train)\n",
    "y_svc=pipe_svc.predict(X_train)\n",
    "print(\"{m:s} Model: f1 score={s:3.2f}\\n\".format(m=\"Decission Tree\", s=f1_score(y_train, y_DT) ) )\n",
    "print(\"{m:s} Model: f1 score={s:3.2f}\\n\".format(m=\"Logistic Regression\", s=f1_score(y_train, y_LR)) )\n",
    "print(\"{m:s} Model: f1 score={s:3.2f}\\n\".format(m=\"SVC\", s=f1_score(y_train, y_svc)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wee can see that our f1 score for all tree model have improved a lot. Rasmaple and balanced the data improved our performance significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "base on the f1 score and cross validation score, I think Decision Tree model is slightly better for this case\n",
    "Now, I will try to tuning the model again as in previous tuning, the distence between params is pretty big, I want to avoid any boundary value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeClassifier(random_state = 42)\n",
    "pipe_DT = Pipeline(steps=[('scaler', scaler),('imputer', imp),\n",
    "                          ('model', DT)])\n",
    "param_grid_DT = {'model__max_features': [26,27,28,29,30,31,32,33,34],\n",
    "              'model__criterion': ['gini', 'entropy'],\n",
    "                'model__max_depth' : [28,29,30,31,32,33,34,35]}\n",
    "grid_DT = GridSearchCV(pipe_DT, param_grid_DT)\n",
    "grid_DT.fit(X_train, y_train)\n",
    "print(grid_DT.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_DT = DecisionTreeClassifier(criterion = \"gini\", random_state = 42,max_depth = 30,max_features = 33)\n",
    "pipe_DT = Pipeline(steps=[('imputer', imp),('scaler', scaler),('model', optimal_DT)])\n",
    "pipe_DT.fit(X_train,y_train)\n",
    "cross_val_scores = cross_val_score(pipe_DT, X_train, y_train, cv=5)\n",
    "print(\"{m:s} Model: avg cross validation score={s:3.2f}\\n\".format(m=\"Decission Tree\", s=cross_val_scores.mean()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So pipe_DT is our best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission guidelines\n",
    "\n",
    "Although your notebook may contain many models (e.g., due to your iterative development)\n",
    "we will only evaluate a single model.\n",
    "So choose one (explain why !) and do the following.\n",
    "\n",
    "- You will implement the body of a subroutine `MyModel`\n",
    "    - That takes as argument a Pandas DataFrame \n",
    "        - Each row is an example on which to predict\n",
    "        - The features of the example are elements of the row\n",
    "    - Performs predictions on each example\n",
    "    - Returns an array or predictions with a one-to-one correspondence with the examples in the test set\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate your model against the holdout data\n",
    "- By reading the holdout examples `X_hold` (as above)\n",
    "- Calling `y_hold_pred = MyModel(X_hold)` to get the predictions\n",
    "- Comparing the predicted values `y_hold_pred` against the true labels `y_hold` which are known only to the instructors\n",
    "\n",
    "See the following cell as an illustration"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Give the model a name (will appear in the print statement)\n",
    "name = \"This is the name I've given to my model\"\n",
    "\n",
    "X_hold = pd.read_csv( os.path.join(DATA_DIR, \"holdout\", '5th_yr.csv') )\n",
    "\n",
    "# Predict using MyModel\n",
    "y_hold_pred = MyModel(X_hold)\n",
    "\n",
    "# Compute metrics\n",
    "# accuracy\n",
    "accuracy_hold = accuracy_score(y_hold, y_hold_pred)\n",
    "\n",
    "# recall_\n",
    "recall_hold = recall_score(y_hold, y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "# precision\n",
    "precision_hold = precision_score(y_hold,   y_hold_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_hold,\n",
    "                                                                            r=recall_hold,\n",
    "                                                                            p=precision_hold\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember**\n",
    "\n",
    "The holdout data is in the same format as the one we used for training\n",
    "- Except that it has no attribute for the target\n",
    "- So you will need to perform all the transformations on the holdout data\n",
    "    - As you did on the training data\n",
    "    - Including turning the string representation of numbers into actual numeric data types\n",
    "\n",
    "All of this work *must* be performed within the body of the `MyModel` routine you will write\n",
    "\n",
    "We will grade you by comparing the predictions array you create to the answers known to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def MyModel(X):\n",
    "    # It should create an array of predictions; we initialize it to the empty array for convenience\n",
    "    predictions = []\n",
    "    \n",
    "    # YOUR CODE GOES HERE\n",
    "    X = X.drop(columns = \"Id\")\n",
    "    X = X.apply(pd.to_numeric, errors='coerce')\n",
    "    predictions = pipe_DT.predict(X)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your work: predict and evaluate metrics on *your* test examples\n",
    "\n",
    "Although only the instructors have the correct labels for the holdout dataset, you may want\n",
    "to create your own test dataset on which to evaluate your out of sample metrics.\n",
    "\n",
    "If you choose to do so, you can evaluate your models using the same metrics that the instructors will use.\n",
    "\n",
    "- Test whether your implementation of `MyModel` works\n",
    "- See the metrics  your model produces\n",
    "\n",
    "The following cell\n",
    "- Assumes that you have created `X_test, y_test` as your proxy for an out of sample dataset\n",
    "    - It serves the same function as `X_hold`, the holdout dataset, but you have the associated target (only the instructors have `y_hold`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the model a name (will appear in the print statement)\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "name = \"Decision Tree Model\"\n",
    "\n",
    "y_test_pred = MyModel(X_test)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred, pos_label=1, average=\"binary\")\n",
    "precision_test = precision_score(y_test,   y_test_pred, pos_label=1, average=\"binary\")\n",
    "\n",
    "print(\"\\t{m:s} Accuracy: {a:3.1%}, Recall {r:3.1%}, Precision {p:3.1%}\".format(m=name,\n",
    "                                                                            a=accuracy_test,\n",
    "                                                                            r=recall_test,\n",
    "                                                                            p=precision_test\n",
    "                                                                            )\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
